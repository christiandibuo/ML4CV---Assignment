{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10068624,"sourceType":"datasetVersion","datasetId":6205623},{"sourceId":10979266,"sourceType":"datasetVersion","datasetId":6824487}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":18050.426876,"end_time":"2025-03-08T21:39:17.103244","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-03-08T16:38:26.676368","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"0473895ea3ad449b95f07219b72e6302":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"064b98ca431f4e40a68e3bdea6f16438":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c8a231bcd5dd4f2a9d26d1cfbd867a59","IPY_MODEL_93432b11c52c47ab96b4e3ac6d6c0fb3","IPY_MODEL_63717869ad784fd4a0eca322b0d1e893"],"layout":"IPY_MODEL_2dfcded0f49c44a1a366c50389348f6a","tabbable":null,"tooltip":null}},"0929269721b640549d84ec197d732b40":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d94643ea55545319f1f4af205f051ae":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0defd40e2f8a4a71b0ec0b46ccf429d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_0929269721b640549d84ec197d732b40","placeholder":"​","style":"IPY_MODEL_51f7b9bc5c2f4e18aae7b5173a3d5daf","tabbable":null,"tooltip":null,"value":"preprocessor_config.json: 100%"}},"1f5038121dd14ee2a2a0e574b77fadf7":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1fb72217b00345d58e7c600b72242ec4":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_82aa587176a246a8a49a84cf68ec157a","IPY_MODEL_9cbce38ffbf64cccbe3e63d8280575da","IPY_MODEL_6cc31ea882bb4a6dac0a1f5e97e3344c"],"layout":"IPY_MODEL_931ad585a297420ca53f1c7dff3ae449","tabbable":null,"tooltip":null}},"1fc02403b4bd4f25898419d6fe49dad4":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"20c2bf9562454150b145ee530d3e9d92":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"240be6074f604da198d9d3d954771a40":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2ab08aec6a0d4dd18e572573fea2b15d":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2dfcded0f49c44a1a366c50389348f6a":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46177473f0ba4a4f9e712f4352a24fa1":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_b31fb209d130455ab455cc36eb305a5d","max":187,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1f5038121dd14ee2a2a0e574b77fadf7","tabbable":null,"tooltip":null,"value":187}},"4957a9b94d5d498285fc46e4f97c111d":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4aa33bbd09e04265a2cc55be12a2708f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9d51a5e9e6f34f51a5a914739e01b96f","IPY_MODEL_78e95fc5affa444397f9222fe47a293f","IPY_MODEL_822b78cff7fa4a37becc4edde4a95483"],"layout":"IPY_MODEL_4957a9b94d5d498285fc46e4f97c111d","tabbable":null,"tooltip":null}},"51f7b9bc5c2f4e18aae7b5173a3d5daf":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"55b6db8708064d7bb944d6704e2520db":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"599f754041b34ba99edc4e996b78f123":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"632a75af43a34255aedb3197c8d1779e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"63717869ad784fd4a0eca322b0d1e893":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_599f754041b34ba99edc4e996b78f123","placeholder":"​","style":"IPY_MODEL_b780174d65ac498d84a65c8bfaae8351","tabbable":null,"tooltip":null,"value":" 12.9k/12.9k [00:00&lt;00:00, 1.18MB/s]"}},"6662e77220ed4d04a6f8d79436bfa0fc":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6cc31ea882bb4a6dac0a1f5e97e3344c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_2ab08aec6a0d4dd18e572573fea2b15d","placeholder":"​","style":"IPY_MODEL_818b7ecbaa3a4e558f8fd9dd0af8e66d","tabbable":null,"tooltip":null,"value":" 1.64k/1.64k [00:00&lt;00:00, 158kB/s]"}},"75c380d3ff944c0bb9ce5f3048351ac0":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"781e8cbacc4a4156ae9e9c5614e1b429":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78e95fc5affa444397f9222fe47a293f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_a068d692f6824c6d9bf248ad05a745b3","max":25615631,"min":0,"orientation":"horizontal","style":"IPY_MODEL_632a75af43a34255aedb3197c8d1779e","tabbable":null,"tooltip":null,"value":25615631}},"7bbace17f953461bade2710047cac276":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"818b7ecbaa3a4e558f8fd9dd0af8e66d":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"822b78cff7fa4a37becc4edde4a95483":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_781e8cbacc4a4156ae9e9c5614e1b429","placeholder":"​","style":"IPY_MODEL_1fc02403b4bd4f25898419d6fe49dad4","tabbable":null,"tooltip":null,"value":" 25.6M/25.6M [00:00&lt;00:00, 177MB/s]"}},"82aa587176a246a8a49a84cf68ec157a":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_0d94643ea55545319f1f4af205f051ae","placeholder":"​","style":"IPY_MODEL_b2b1693e902842de92324d935f7239a3","tabbable":null,"tooltip":null,"value":"config.json: 100%"}},"8fe054ed1fd14f1f95d09c82cfae3821":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"903e169af3a642f2a63164b0e2b07557":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_6662e77220ed4d04a6f8d79436bfa0fc","placeholder":"​","style":"IPY_MODEL_0473895ea3ad449b95f07219b72e6302","tabbable":null,"tooltip":null,"value":" 187/187 [00:00&lt;00:00, 17.3kB/s]"}},"931ad585a297420ca53f1c7dff3ae449":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93432b11c52c47ab96b4e3ac6d6c0fb3":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_edaf9a05755746a08fb491a78dbbedbf","max":12929,"min":0,"orientation":"horizontal","style":"IPY_MODEL_240be6074f604da198d9d3d954771a40","tabbable":null,"tooltip":null,"value":12929}},"9cbce38ffbf64cccbe3e63d8280575da":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_8fe054ed1fd14f1f95d09c82cfae3821","max":1644,"min":0,"orientation":"horizontal","style":"IPY_MODEL_75c380d3ff944c0bb9ce5f3048351ac0","tabbable":null,"tooltip":null,"value":1644}},"9d51a5e9e6f34f51a5a914739e01b96f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_f7577edc985b4426a40885aa52033c3f","placeholder":"​","style":"IPY_MODEL_20c2bf9562454150b145ee530d3e9d92","tabbable":null,"tooltip":null,"value":"pytorch_model.bin: 100%"}},"a068d692f6824c6d9bf248ad05a745b3":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a93b67af89fd4fb391496e0dfc13e38e":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2b1693e902842de92324d935f7239a3":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"b31fb209d130455ab455cc36eb305a5d":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b780174d65ac498d84a65c8bfaae8351":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"c8a231bcd5dd4f2a9d26d1cfbd867a59":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_a93b67af89fd4fb391496e0dfc13e38e","placeholder":"​","style":"IPY_MODEL_55b6db8708064d7bb944d6704e2520db","tabbable":null,"tooltip":null,"value":"Downloading builder script: 100%"}},"d9e3d2146d544424b3c0779bf17f1956":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0defd40e2f8a4a71b0ec0b46ccf429d2","IPY_MODEL_46177473f0ba4a4f9e712f4352a24fa1","IPY_MODEL_903e169af3a642f2a63164b0e2b07557"],"layout":"IPY_MODEL_7bbace17f953461bade2710047cac276","tabbable":null,"tooltip":null}},"edaf9a05755746a08fb491a78dbbedbf":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7577edc985b4426a40885aa52033c3f":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Author\n0001128790 - Christian Di Buò - christian.dibuo@studio.unibo.it","metadata":{"papermill":{"duration":0.003112,"end_time":"2025-03-08T16:38:29.244533","exception":false,"start_time":"2025-03-08T16:38:29.241421","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### Importing images","metadata":{"papermill":{"duration":0.002288,"end_time":"2025-03-08T16:38:29.249659","exception":false,"start_time":"2025-03-08T16:38:29.247371","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os, json\nimport subprocess, sys\nimport random\nimport math\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nimport numpy as np\nfrom tqdm import tqdm\nimport copy\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom transformers import MobileViTImageProcessor, MobileViTForSemanticSegmentation","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":7.525073,"end_time":"2025-03-08T16:38:36.777134","exception":false,"start_time":"2025-03-08T16:38:29.252061","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"package_name = \"evaluate\"\n\ntry:\n    __import__(package_name)\n    print('already installed')\nexcept ImportError:\n    print(f\"{package_name} is NOT installed! Installing now...\")\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name]);","metadata":{"papermill":{"duration":4.423216,"end_time":"2025-03-08T16:38:41.203293","exception":false,"start_time":"2025-03-08T16:38:36.780077","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def fix_random(seed: int) -> None:\n    \"\"\"Fix all the possible sources of randomness.\n\n    Args:\n        seed: the seed to use.\n    \"\"\"\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\n\nfix_random(seed=42)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import evaluate\n\n\"\"\"\nSource: https://github.com/hendrycks/anomaly-seg/issues/15#issuecomment-890300278\n\"\"\"\nCOLORS = np.array([\n    [  0,   0,   0],  # unlabeled    =   0,\n    [ 70,  70,  70],  # building     =   1,\n    [190, 153, 153],  # fence        =   2, \n    [250, 170, 160],  # other        =   3,\n    [220,  20,  60],  # pedestrian   =   4, \n    [153, 153, 153],  # pole         =   5,\n    [157, 234,  50],  # road line    =   6, \n    [128,  64, 128],  # road         =   7,\n    [244,  35, 232],  # sidewalk     =   8,\n    [107, 142,  35],  # vegetation   =   9, \n    [  0,   0, 142],  # car          =  10,\n    [102, 102, 156],  # wall         =  11, \n    [220, 220,   0],  # traffic sign =  12,\n    [ 60, 250, 240],  # anomaly      =  13,\n]) ","metadata":{"papermill":{"duration":15.996979,"end_time":"2025-03-08T16:38:57.203315","exception":false,"start_time":"2025-03-08T16:38:41.206336","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class StreetHazardsDataset(Dataset):\n    def __init__(self, odgt_file, transform1=None, transform2=None):\n        \"\"\"\n        Args:\n            odgt_file (str): Path to the .odgt file (train, val, or test).\n            transform (callable, optional): Transformations to apply to images and masks.\n        \"\"\"\n\n        self.transform1 = transform1\n        self.transform2 = transform2\n\n        # Load the .odgt file\n        with open(odgt_file, \"r\") as f:\n            odgt_data = json.load(f)\n\n        self.paths = [\n            {\n                \"image\": os.path.join(Path(odgt_file).parent, data[\"fpath_img\"]),\n                \"annotation\": os.path.join(Path(odgt_file).parent, data[\"fpath_segm\"]),\n            }\n            for data in odgt_data \n        ]\n\n    def __len__(self):\n        return len(self.paths)\n\n    def __getitem__(self, idx):\n\n        # Build full paths for image and mask\n        image = Image.open(self.paths[idx][\"image\"]).convert(\"RGB\")\n        annotation = Image.open(self.paths[idx][\"annotation\"])\n\n        if self.transform1:\n            image = self.transform1(image)\n            annotation = torch.as_tensor(transforms.functional.pil_to_tensor(annotation), dtype=torch.int64) - 1 # Make class indexes start from 0\n            annotation = self.transform2(annotation).squeeze(0)\n\n        return {'image' : image, 'labels' : annotation}\n\n\ndef visualize_annotation(annotation_img: np.ndarray|torch.Tensor, ax=None):\n    \"\"\"\n    Adapted from https://github.com/CVLAB-Unibo/ml4cv-assignment/blob/master/utils/visualize.py\n    \"\"\"\n    if ax is None: ax = plt.gca()\n    annotation_img = np.asarray(annotation_img)\n    img_new = np.zeros((*annotation_img.shape, 3))\n\n    for index, color in enumerate(COLORS):\n        img_new[annotation_img == index] = color\n\n    ax.imshow(img_new / 255.0)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\ndef visualize_scene(image: np.ndarray|torch.Tensor, ax=None):\n    if ax is None: ax = plt.gca()\n    image = np.asarray(image)\n    ax.imshow(np.moveaxis(image, 0, -1))\n    ax.set_xticks([])\n    ax.set_yticks([])\n\n","metadata":{"papermill":{"duration":0.013097,"end_time":"2025-03-08T16:38:57.219639","exception":false,"start_time":"2025-03-08T16:38:57.206542","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transform1 = transforms.Compose([\n    transforms.Resize((520, 520), transforms.InterpolationMode.NEAREST),\n    transforms.ToTensor()\n])\n\ntransform2 = transforms.Compose([\n    transforms.Resize((520, 520), transforms.InterpolationMode.NEAREST)\n])\n\n# Create dataset instance\ntrain_dataset = StreetHazardsDataset(\n    odgt_file=\"/kaggle/input/ml4cv-data/streethazards_train/train/train.odgt\",\n    transform1=transform1,\n    transform2=transform2\n)\nval_dataset = StreetHazardsDataset(\n    odgt_file=\"/kaggle/input/ml4cv-data/streethazards_train/train/validation.odgt\",\n    transform1=transform1,\n    transform2=transform2\n)\ntest_dataset = StreetHazardsDataset(\n    odgt_file=\"/kaggle/input/ml4cv-data/streethazards_test/test/test.odgt\",\n    transform1=transform1,\n    transform2=transform2\n)","metadata":{"papermill":{"duration":0.121557,"end_time":"2025-03-08T16:38:57.343956","exception":false,"start_time":"2025-03-08T16:38:57.222399","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"idx = random.randint(0, len(test_dataset))\nprint(test_dataset[idx]['labels'].shape, len(test_dataset))\nvisualize_annotation(test_dataset[idx]['labels'])","metadata":{"papermill":{"duration":0.488067,"end_time":"2025-03-08T16:38:57.835085","exception":false,"start_time":"2025-03-08T16:38:57.347018","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def as_numpy(obj):\n    if torch.is_tensor(obj):\n        return obj.cpu().numpy()\n    else:\n        return np.array(obj)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_model(model_name, num_classes, weights_path = None):\n    \n    if not weights_path:\n        weights_path = model_name\n        \n    feature_extractor = MobileViTImageProcessor.from_pretrained(model_name)\n    model = MobileViTForSemanticSegmentation.from_pretrained(weights_path, num_labels=num_classes, ignore_mismatched_sizes=True, semantic_loss_ignore_index = 13)\n    \n    model.to(DEVICE);\n    \n    return model","metadata":{"papermill":{"duration":1.989493,"end_time":"2025-03-08T16:38:59.829043","exception":false,"start_time":"2025-03-08T16:38:57.839550","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MeanIoU:\n    \"\"\"\n    taken from https://github.com/Jun-CEN/Open-World-Semantic-Segmentation/blob/main/DeepLabV3Plus-Pytorch/metrics/stream_metrics.py\n    \"\"\"\n    def __init__(self, n_classes= 13):\n        self.n_classes = n_classes\n        self.confusion_matrix = np.zeros((n_classes, n_classes))\n        \n    def update(self, label_trues, logits):\n        label_preds = torch.argmax(logits, dim=1)\n        label_preds, label_trues = label_preds.cpu().numpy(), label_trues.cpu().numpy()\n        for lt, lp in zip(label_trues, label_preds):\n            self.confusion_matrix += self._fast_hist( lt.flatten(), lp.flatten())\n\n    def _fast_hist(self, label_true, label_pred):\n        mask = (label_true >= 0) & (label_true < self.n_classes)\n        hist = np.bincount(\n            self.n_classes * label_true[mask].astype(int) + label_pred[mask],\n            minlength=self.n_classes ** 2,\n        ).reshape(self.n_classes, self.n_classes)\n        return hist\n\n    def get_results(self):\n        \"\"\"Returns accuracy score evaluation result.\n            - overall accuracy\n            - mean accuracy\n            - mean IU\n            - fwavacc\n        \"\"\"\n        hist = self.confusion_matrix\n        acc = np.diag(hist).sum() / hist.sum()\n        acc_cls = np.diag(hist) / hist.sum(axis=1)\n        acc_cls = np.nanmean(acc_cls)\n        iu = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n        mean_iu = np.nanmean(iu, axis= 0)\n        freq = hist.sum(axis=1) / hist.sum()\n        fwavacc = (freq[freq > 0] * iu[freq > 0]).sum()\n        cls_iu = dict(zip(range(self.n_classes), iu))\n\n        return {\n                \"Overall Acc\": acc,\n                \"Mean Acc\": acc_cls,\n                \"FreqW Acc\": fwavacc,\n                \"Mean IoU\": mean_iu,\n                \"Class IoU\": cls_iu,\n            }\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import sklearn.metrics as sk\n\ndef get_aupr(confs, seg_labels, out_label=13):\n\n    aupr = []\n    seg_labels = as_numpy(seg_labels)\n    \n    for conf, seg_label in zip(confs, seg_labels):\n\n        out_label = out_label\n        in_scores = - conf[np.where(seg_label == out_label)]\n        out_scores  = - conf[np.where(seg_label != out_label)]\n    \n        if (len(out_scores) != 0) and (len(in_scores) != 0):\n            \n            pos = np.array(in_scores[:]).reshape((-1, 1))\n            neg = np.array(out_scores[:]).reshape((-1, 1))\n            examples = np.squeeze(np.vstack((pos, neg)))\n            labels = np.zeros(len(examples), dtype=np.int32)\n            labels[:len(pos)] += 1\n        \n            aupr.append(sk.average_precision_score(labels, examples))\n\n        aupr = np.mean(aupr)\n        return aupr * 100","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from kornia.morphology import dilation, erosion\nfrom scipy import ndimage as ndi\n\nd_k1 = torch.zeros((1, 1, 2 * 1 + 1, 2 * 1 + 1)).cuda()\nd_k2 = torch.zeros((1, 1, 2 * 2 + 1, 2 * 2 + 1)).cuda()\nd_k3 = torch.zeros((1, 1, 2 * 3 + 1, 2 * 3 + 1)).cuda()\nd_k4 = torch.zeros((1, 1, 2 * 4 + 1, 2 * 4 + 1)).cuda()\nd_k5 = torch.zeros((1, 1, 2 * 5 + 1, 2 * 5 + 1)).cuda()\nd_k6 = torch.zeros((1, 1, 2 * 6 + 1, 2 * 6 + 1)).cuda()\nd_k7 = torch.zeros((1, 1, 2 * 7 + 1, 2 * 7 + 1)).cuda()\nd_k8 = torch.zeros((1, 1, 2 * 8 + 1, 2 * 8 + 1)).cuda()\nd_k9 = torch.zeros((1, 1, 2 * 9 + 1, 2 * 9 + 1)).cuda()\n\nd_ks = {1: d_k1, 2: d_k2, 3: d_k3, 4: d_k4, 5: d_k5, 6: d_k6, 7: d_k7, 8: d_k8, 9: d_k9}\n\n\nselem = torch.ones((3, 3)).cuda()\nselem_dilation = torch.FloatTensor(ndi.generate_binary_structure(2, 1)).cuda()\n\nfor k, v in d_ks.items():\n    v[:,:,k,k] = 1\n    for i in range(k):\n        v = dilation(v, selem_dilation)\n    d_ks[k] = v.squeeze(0).squeeze(0)\n\ndef find_boundaries(label):\n    \"\"\"\n    Calculate boundary mask by getting diff of dilated and eroded prediction maps\n    \"\"\"\n    assert len(label.shape) == 4\n    boundaries = (dilation(label.float(), selem_dilation) != erosion(label.float(), selem)).float()\n    ### save_image(boundaries, f'boundaries_{boundaries.float().mean():.2f}.png', normalize=True)\n\n    return boundaries\n\ndef expand_boundaries(boundaries, r=0):\n    \"\"\"\n    Expand boundary maps with the rate of r\n    \"\"\"\n    if r == 0:\n        return boundaries\n    expanded_boundaries = dilation(boundaries, d_ks[r])\n    ### save_image(expanded_boundaries, f'expanded_boundaries_{r}_{boundaries.float().mean():.2f}.png', normalize=True)\n    return expanded_boundaries","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class BoundarySuppressionWithSmoothing(nn.Module):\n    \"\"\"\n    Apply boundary suppression and dilated smoothing\n    \"\"\"\n    def __init__(self, boundary_suppression=True, boundary_width=4, boundary_iteration=4,\n                 dilated_smoothing=True, kernel_size=7, dilation=6):\n        super(BoundarySuppressionWithSmoothing, self).__init__()\n        self.kernel_size = kernel_size\n        self.dilation = dilation\n        self.boundary_suppression = boundary_suppression\n        self.boundary_width = boundary_width\n        self.boundary_iteration = boundary_iteration\n\n        sigma = 1.0\n        size = 7\n        gaussian_kernel = np.fromfunction(lambda x, y: (1/(2*math.pi*sigma**2)) * math.e ** ((-1*((x-(size-1)/2)**2+(y-(size-1)/2)**2))/(2*sigma**2)), (size, size))\n        gaussian_kernel /= np.sum(gaussian_kernel)\n        gaussian_kernel = torch.Tensor(gaussian_kernel).unsqueeze(0).unsqueeze(0)\n        self.dilated_smoothing = dilated_smoothing\n\n        self.first_conv = nn.Conv2d(1, 1, kernel_size=3, stride=1, bias=False)\n        self.first_conv.weight = torch.nn.Parameter(torch.ones_like((self.first_conv.weight)))\n\n        self.second_conv = nn.Conv2d(1, 1, kernel_size=self.kernel_size, stride=1, dilation=self.dilation, bias=False)\n        self.second_conv.weight = torch.nn.Parameter(gaussian_kernel)\n\n\n    def forward(self, x, prediction=None):\n        if len(x.shape) == 3:\n            x = x.unsqueeze(1)\n        x_size = x.size()\n        # B x 1 x H x W\n        assert len(x.shape) == 4\n        out = x\n        if self.boundary_suppression:\n            # obtain the boundary map of width 2 by default\n            # this can be calculated by the difference of dilation and erosion\n            boundaries = find_boundaries(prediction.unsqueeze(1))\n            expanded_boundaries = None\n            if self.boundary_iteration != 0:\n                assert self.boundary_width % self.boundary_iteration == 0\n                diff = self.boundary_width // self.boundary_iteration\n            for iteration in range(self.boundary_iteration):\n                if len(out.shape) != 4:\n                    out = out.unsqueeze(1)\n                prev_out = out\n                # if it is the last iteration or boundary width is zero\n                if self.boundary_width == 0 or iteration == self.boundary_iteration - 1:\n                    expansion_width = 0\n                # reduce the expansion width for each iteration\n                else:\n                    expansion_width = self.boundary_width - diff * iteration - 1\n                # expand the boundary obtained from the prediction (width of 2) by expansion rate\n                expanded_boundaries = expand_boundaries(boundaries, r=expansion_width)\n                # invert it so that we can obtain non-boundary mask\n                non_boundary_mask = 1. * (expanded_boundaries == 0)\n\n                f_size = 1\n                num_pad = f_size\n\n                # making boundary regions to 0\n                x_masked = out * non_boundary_mask\n                x_padded = nn.ReplicationPad2d(num_pad)(x_masked)\n\n                non_boundary_mask_padded = nn.ReplicationPad2d(num_pad)(non_boundary_mask)\n\n                # sum up the values in the receptive field\n                y = self.first_conv(x_padded)\n                # count non-boundary elements in the receptive field\n                num_calced_elements = self.first_conv(non_boundary_mask_padded)\n                num_calced_elements = num_calced_elements.long()\n\n                # take an average by dividing y by count\n                # if there is no non-boundary element in the receptive field,\n                # keep the original value\n                avg_y = torch.where((num_calced_elements == 0), prev_out, y / num_calced_elements)\n                out = avg_y\n\n                # update boundaries only\n                out = torch.where((non_boundary_mask == 0), out, prev_out)\n                del expanded_boundaries, non_boundary_mask\n\n            # second stage; apply dilated smoothing\n            if self.dilated_smoothing == True:\n                out = nn.ReplicationPad2d(self.dilation * 3)(out)\n                out = self.second_conv(out)\n\n            return out.squeeze(1)\n        else:\n            if self.dilated_smoothing == True:\n                out = nn.ReplicationPad2d(self.dilation * 3)(out)\n                out = self.second_conv(out)\n            else:\n                out = x\n\n        return out.squeeze(1)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Trainer:\n    def __init__(self,\n                 model: nn.Module,\n                 train_loader: DataLoader,\n                 val_loader: DataLoader,\n                 device: torch.device,\n                 num_classes: int,\n                 cfg: dict,\n                 model_name: str,\n                 resume_ckpt: dict = None,\n                 \n        ) -> None:\n        \n        self.model_name = model_name\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        self.device = device\n        self.num_classes = num_classes\n        self.patience = cfg[\"patience\"]\n        self.multi_scale = BoundarySuppressionWithSmoothing()\n        self.multi_scale.to(DEVICE)\n        \n        if resume_ckpt:\n            self.mean_iou = cfg['mean_iou']\n            self.num_epochs = cfg[\"num_epochs\"] - resume_ckpt['epoch']\n            #self.loss = \n            self.model = resume_ckpt['model_state_dict']\n            self.optimizer = resume_ckpt['optimizer_state_dict']\n            self.scheduler = resume_ckpt['scheduler_state_dict']\n\n        else:\n            self.mean_iou = 0.0\n            self.num_epochs = cfg[\"num_epochs\"]\n            self.model = model.to(device)\n            self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=cfg[\"lr\"], weight_decay=cfg[\"wd\"])\n            num_steps = self.num_epochs * len(train_loader)\n            self.scheduler = torch.optim.lr_scheduler.OneCycleLR(self.optimizer, cfg[\"lr\"], total_steps=num_steps)\n\n        self.step = 0\n        self.best_acc = 0.0\n        \n        #wandb.init(name=cfg[\"run_name\"], entity=WANDB_USER, project=WANDB_PROJECT, config=cfg)\n        self.ckpt_path = Path(\"ckpts\")\n        self.ckpt_path.mkdir(exist_ok=True)\n\n    '''def logfn(self, values: Dict[str, Any]) -> None:\n        wandb.log(values, step=self.step, commit=False)'''\n\n    def train(self, verbose= False) -> None:\n        for epoch in tqdm(range(self.num_epochs), desc=\"Epoch\"):\n            \n            self.model.train()\n\n            for batch in self.train_loader:\n                imgs = batch['image'].to(self.device)\n                labels = batch['labels'].to(self.device)\n\n                pred = self.model(imgs)\n                logits = F.interpolate(pred['logits'], size=labels.shape[1:], mode='bilinear', align_corners=False)\n                loss = F.cross_entropy(logits, labels)\n\n                self.optimizer.zero_grad()\n                loss.backward()\n                self.optimizer.step()\n                self.scheduler.step()\n\n                '''if self.step % 10 == 0:\n                    self.logfn({\"train/loss\": loss.item()})\n                    self.logfn({\"train/lr\": self.scheduler.get_last_lr()[0]})'''\n\n            self.eval(\"train\", epoch)\n            self.eval(\"val\", epoch)\n\n            if self.patience < self.step:\n                break\n        \n        #return torch.load(self.ckpt_path / \"model_weights\"/f\"{self.model_name}.pt\")\n\n    @torch.no_grad()\n    def eval(self, split: str, epoch: int) -> None:\n        \n        self.model.eval()\n\n        loader = self.train_loader if split == \"train\" else self.val_loader\n        \n        mean_iou = MeanIoU()\n        losses = []\n        mean_avg = []\n        std_avg = []\n        \n        for batch in loader:\n            imgs = batch['image'].to(self.device)\n            labels = batch['labels'].to(self.device)\n\n            pred = self.model(imgs)\n\n            logits = F.interpolate(pred['logits'], size=labels.shape[1:], mode='bilinear', align_corners=False)\n            loss = F.cross_entropy(logits, labels)\n            \n            losses.append(loss.item())\n\n            mean_iou.update(labels, logits)\n\n        results = mean_iou.get_results()\n        mean_iou = results['Mean IoU']\n        loss = sum(losses) / len(losses)\n\n        if mean_iou > self.mean_iou and split == \"val\":\n            self.mean_iou = mean_iou\n            torch.save(self.model.state_dict(), self.ckpt_path/f\"{self.model_name}.pt\")\n            torch.save({\n                'epoch': epoch,\n                'mean_iou': self.mean_iou,\n                #'loss': loss,\n                'model_state_dict': self.model.state_dict(),\n                'optimizer_state_dict': self.optimizer.state_dict(),\n                'scheduler_state_dict': self.scheduler.state_dict(),\n                }, self.ckpt_path / \"best_checkpoint\")\n            \n            self.best_model = copy.deepcopy(self.model)\n            self.step = 0\n\n        else:\n            self.step += 1\n    \n    @torch.no_grad()\n    def predict(self, loader, verbose= False):\n\n        self.model.eval()\n        mean_iou = MeanIoU()\n        aupr = []\n\n        mean_logit = []\n        std_logit = []\n        \n        for batch in tqdm(loader):\n            imgs = batch['image'].to(self.device)\n            labels_true = batch['labels'].to(self.device)\n            pred = self.model(imgs)\n            logits = F.interpolate(pred['logits'], size=labels_true.shape[1:], mode='bilinear', align_corners=False)\n            mean_iou.update(labels_true, logits)\n\n            '''mean, std = get_mean_std(logits)\n            mean_logit.append(mean)\n            std_logit.append(std)\n            return np.mean(mean_logit, axis = 0), np.mean(std_logit, axis = 0)'''\n\n            \"\"\"\n            predictors\n            \"\"\"\n            \n            conf = maximum_softmax_probability(logits, self.multi_scale)\n            #conf = max_logit(logits, self.multi_scale)\n            #conf = euclidean_distance_sum(logits)\n            \n            '''conf = standardized_max_logit(logits, self.multi_scale,\n                                          class_mean = MEAN_PER_CLASS, \n                                          class_var = VAR_PER_CLASS)'''\n\n            conf = as_numpy(conf.squeeze(0).cpu())\n\n            \n            aupr.append(get_aupr(conf, labels_true))\n\n        \n        #pred_labels = pred_labels.cpu().numpy()\n        return np.mean(aupr), mean_iou.get_results()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_mean_std(logits, num_classes = 13):\n\n    mean_avg = np.zeros(13)\n    std_avg = np.zeros(13)\n    \n    for logit in logits:\n        conf, labels = torch.max(logit, 0)\n        for c in range(num_classes):\n            tens = torch.where(labels == c, conf, 0)\n            mean, std = torch.std_mean(tens)\n\n            mean_avg[c] += as_numpy(mean)\n            std_avg[c] += as_numpy(std)\n\n    return mean_avg, std_avg**2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def maximum_softmax_probability(logits, multi_scale = None):\n    \"\"\"\n    taken from https://github.com/Jun-CEN/Open-World-Semantic-Segmentation/blob/main/anomaly/eval_ood_traditional.py#L185\n    \"\"\"\n    conf, prediction  = torch.max(nn.functional.softmax(logits, dim=1),dim=1)\n\n    #taken from standardized max logit\n    if multi_scale:\n        with torch.no_grad():\n            conf = multi_scale(conf, prediction)\n    \n    return conf","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def max_logit(logits, multi_scale = None):\n    \"\"\"\n    taken from https://github.com/Jun-CEN/Open-World-Semantic-Segmentation/blob/main/anomaly/eval_ood_traditional.py#L185\n    \"\"\"\n    conf, prediction  = torch.max(logits,dim=1)\n    \n    #taken from standardized max logit\n    if multi_scale:\n        with torch.no_grad():\n            conf = multi_scale(conf, prediction)\n\n    return conf","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def standardized_max_logit(logits, multi_scale, class_mean, class_var, num_classes = 13):\n\n\n    conf, prediction  = torch.max(logits,dim=1)\n    for c in range(num_classes):\n        conf = torch.where(\n            prediction == c,\n            (conf - class_mean[c]) / np.sqrt(class_var[c]),\n            conf)\n\n    if multi_scale:\n        with torch.no_grad():\n            conf = multi_scale(conf, prediction)\n\n    return conf","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def euclidean_distance_sum(logits):\n    \n    \"\"\"\n    taken from https://github.com/Jun-CEN/Open-World-Semantic-Segmentation/blob/main/anomaly/eval_ood_traditional.py#L185\n    \"\"\"\n\n    def Normalization(x):\n        return (x - np.min(x)) / (np.max(x) - np.min(x))\n\n    def Coefficient_map(x, thre):\n        lamda = 50\n        return 1 / (1 + np.exp(lamda * (x - thre)))\n        \n    dis_sum = torch.sum(logits,dim=1)\n    dis_sum = - as_numpy(dis_sum.squeeze(0).cpu())\n    dis_sum[dis_sum >= 400] = 400\n    dis_sum = Normalization(dis_sum)\n    prob_map = np.max(nn.functional.softmax(logits, dim=1).squeeze().cpu().numpy(), axis=1)\n    prob_map = Normalization(prob_map)\n    Coefficient = Coefficient_map(dis_sum, 0.2)\n    conf = Coefficient * dis_sum + (1 - Coefficient) * prob_map\n    conf = dis_sum\n\n    return conf","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### get the model\n\nonly specify the weights path if you do not want to train the model","metadata":{}},{"cell_type":"code","source":"model_name = \"apple/deeplabv3-mobilevit-small\"\n#weights_path = \"/kaggle/input/weights/run_08_03_25 epochs 20-50\"\nweights_path = None\nmodel = get_model(model_name, num_classes = len(COLORS)-1, weights_path = weights_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dl = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)\nval_dl = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=2)\ntest_dl = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### model training","metadata":{}},{"cell_type":"code","source":"cfg = {\n    \"num_epochs\" : 100,\n    \"lr\": 2e-4,\n    \"wd\": 0.001,\n    \"patience\": 10,\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer = Trainer(\n    model= model,\n    train_loader= train_dl,\n    val_loader= val_dl ,\n    device= DEVICE,\n    num_classes = len(COLORS)-1,\n    model_name = 'deeplab',\n    cfg= cfg\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"MEAN_PER_CLASS = [1.72267947e+01, 7.66881425e+00, 5.77455433e-01, 4.47677614e-02,\n 0.00000000e+00, 3.41044600e-01, 1.39990459e+00, 2.11263614e+01,\n 7.31018189e+00, 7.46783295e+00, 1.15309967e-02, 2.41669891e+00,\n 0.00000000e+00]\nVAR_PER_CLASS = [1.33243940e+02, 1.53900278e+01, 2.14974713e-02, 3.87089461e-05,\n 0.00000000e+00, 7.03953145e-03, 8.06856298e-02, 2.19127594e+02,\n 5.62604913e+00, 8.48272837e+00, 1.52454267e-05, 8.70028476e-01,\n 0.00000000e+00]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result = trainer.predict(test_dl)\nprint(result[0])\nprint(result[1])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result = trainer.predict(test_dl)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### AUPR Results:\n- standardized max logit is the worst performer: 6.11 (if use boundiary suppression it goes up to 7.sth)\n- max logit: 7.65\n- maximum softmax probability: 11.33\n- euclidean distance: 15.31","metadata":{}},{"cell_type":"code","source":"print(result[0])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(result[1])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### TODO: inside the train insert the patience (DONE)\n### TODO: implement the checkpoint inside the training to resume from the log (remember to update, scheduler, optimizer and model weights .pt files) (DONE)\n### TODO: implement class AUPR\n### TODO: make anomaly predictions using: \n    - max softmax probability\n    - max logits\n### TODO: create the metrics as class, not as function; you would like to have mean_iou and aupr","metadata":{}}]}